{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import *\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_DIR / \"anti_saccade_processed.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/971070164.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .ffill()\n"
     ]
    }
   ],
   "source": [
    "reaction_time_df = (df\n",
    " .query(\"stimulus_active == True\")\n",
    " .sort_values(by=[\"participant_id\", \"trial_id\", \"stand_time\"])\n",
    " .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.stand_time, None]))\n",
    " .ffill()\n",
    " .query(\"event == 'ESACC'\")\n",
    " .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    " .first()\n",
    " .reset_index()\n",
    " .assign(reaction_time = lambda x: x.stand_start_time - x.stimulus_time)\n",
    " .groupby([\"experiment\",\"participant_id\"])\n",
    " .agg(mean_reaction_time = ('reaction_time', 'mean'))\n",
    " .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function mean at 0x1107d3b00> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function min at 0x1107d3240> is currently using SeriesGroupBy.min. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"min\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function max at 0x1107d3100> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function median at 0x1138468e0> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function std at 0x1107d3c40> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_13340/3287675264.py:2: FutureWarning: The provided callable <function mean at 0x1107d3b00> is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n"
     ]
    }
   ],
   "source": [
    "features = (df.groupby([\"experiment\", \"participant_id\"])\n",
    " .agg({'peak_velocity': [np.mean, np.min, np.max, np.median, np.std],\n",
    "       'amplitude': [np.mean, np.min, np.max, np.median, np.std],\n",
    "       'duration': [np.mean, np.min, np.max, np.median, np.std],\n",
    "       'avg_pupil_size': [np.mean, np.min, np.max, np.median, np.std]\n",
    "       })\n",
    " .reset_index()\n",
    ")\n",
    "    \n",
    "features.columns = [''.join(col).strip() for col in features.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.merge(features, reaction_time_df, left_on=[\"experiment\",\"participant_id\"], right_on=[\"experiment\", \"participant_id\"], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pd.read_excel(DATA_DIR / \"demographic_info.xlsx\")[[\"ID\", \"Group\"]]\n",
    "\n",
    "demographics[\"y\"] = (demographics[\"Group\"] == \"PATIENT\").astype(int)\n",
    "demographics[\"participant_id\"] = demographics[\"ID\"].astype(str)\n",
    "demographics = demographics[[\"participant_id\", \"y\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(features, demographics, how='left', on='participant_id')\n",
    "y_data = data[\"y\"]\n",
    "X_data = data.drop([\"experiment\", \"participant_id\", \"y\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5882352941176471\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "columns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importances",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f3374a4e-4d5c-4527-bf42-7e5f5a9403de",
       "rows": [
        [
         "13",
         "durationmedian",
         "0.08910867"
        ],
        [
         "3",
         "peak_velocitymedian",
         "0.082237795"
        ],
        [
         "16",
         "avg_pupil_sizemin",
         "0.07596759"
        ],
        [
         "9",
         "amplitudestd",
         "0.06857392"
        ],
        [
         "10",
         "durationmean",
         "0.06657061"
        ],
        [
         "12",
         "durationmax",
         "0.064284176"
        ],
        [
         "8",
         "amplitudemedian",
         "0.06049823"
        ],
        [
         "20",
         "mean_reaction_time",
         "0.059415508"
        ],
        [
         "2",
         "peak_velocitymax",
         "0.05713777"
        ],
        [
         "6",
         "amplitudemin",
         "0.056530785"
        ],
        [
         "19",
         "avg_pupil_sizestd",
         "0.053489994"
        ],
        [
         "18",
         "avg_pupil_sizemedian",
         "0.05257136"
        ],
        [
         "15",
         "avg_pupil_sizemean",
         "0.04884002"
        ],
        [
         "5",
         "amplitudemean",
         "0.041264992"
        ],
        [
         "11",
         "durationmin",
         "0.031821813"
        ],
        [
         "14",
         "durationstd",
         "0.02736605"
        ],
        [
         "7",
         "amplitudemax",
         "0.016370337"
        ],
        [
         "17",
         "avg_pupil_sizemax",
         "0.016064858"
        ],
        [
         "0",
         "peak_velocitymean",
         "0.0151875205"
        ],
        [
         "1",
         "peak_velocitymin",
         "0.010671642"
        ],
        [
         "4",
         "peak_velocitystd",
         "0.006026381"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 21
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>durationmedian</td>\n",
       "      <td>0.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>peak_velocitymedian</td>\n",
       "      <td>0.082238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>avg_pupil_sizemin</td>\n",
       "      <td>0.075968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>amplitudestd</td>\n",
       "      <td>0.068574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>durationmean</td>\n",
       "      <td>0.066571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>durationmax</td>\n",
       "      <td>0.064284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>amplitudemedian</td>\n",
       "      <td>0.060498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mean_reaction_time</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>peak_velocitymax</td>\n",
       "      <td>0.057138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amplitudemin</td>\n",
       "      <td>0.056531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>avg_pupil_sizestd</td>\n",
       "      <td>0.053490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>avg_pupil_sizemedian</td>\n",
       "      <td>0.052571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>avg_pupil_sizemean</td>\n",
       "      <td>0.048840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amplitudemean</td>\n",
       "      <td>0.041265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>durationmin</td>\n",
       "      <td>0.031822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>durationstd</td>\n",
       "      <td>0.027366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amplitudemax</td>\n",
       "      <td>0.016370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>avg_pupil_sizemax</td>\n",
       "      <td>0.016065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peak_velocitymean</td>\n",
       "      <td>0.015188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peak_velocitymin</td>\n",
       "      <td>0.010672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>peak_velocitystd</td>\n",
       "      <td>0.006026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 columns  importances\n",
       "13        durationmedian     0.089109\n",
       "3    peak_velocitymedian     0.082238\n",
       "16     avg_pupil_sizemin     0.075968\n",
       "9           amplitudestd     0.068574\n",
       "10          durationmean     0.066571\n",
       "12           durationmax     0.064284\n",
       "8        amplitudemedian     0.060498\n",
       "20    mean_reaction_time     0.059416\n",
       "2       peak_velocitymax     0.057138\n",
       "6           amplitudemin     0.056531\n",
       "19     avg_pupil_sizestd     0.053490\n",
       "18  avg_pupil_sizemedian     0.052571\n",
       "15    avg_pupil_sizemean     0.048840\n",
       "5          amplitudemean     0.041265\n",
       "11           durationmin     0.031822\n",
       "14           durationstd     0.027366\n",
       "7           amplitudemax     0.016370\n",
       "17     avg_pupil_sizemax     0.016065\n",
       "0      peak_velocitymean     0.015188\n",
       "1       peak_velocitymin     0.010672\n",
       "4       peak_velocitystd     0.006026"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", XGBClassifier(n_estimators=10, max_depth=6, learning_rate=1, objective='binary:logistic'))\n",
    "])\n",
    "\n",
    "print(pipe.fit(X_train, y_train).score(X_test, y_test))\n",
    "\n",
    "results=pd.DataFrame()\n",
    "results['columns']=X_train.columns\n",
    "results['importances'] = pipe[\"clf\"].feature_importances_\n",
    "results.sort_values(by='importances',ascending=False,inplace=True)\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
