{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import *\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from functools import reduce\n",
    "df_event = pd.read_parquet(PREPROCESSED_DIR / \"anti_saccade_preprocessed_from_r.pq\")\n",
    "df_sample = (pd.read_parquet(RAW_DIR / 'ANTI_SACCADE_SAMPLES.pq')\n",
    " .sort_values([\"experiment\", \"participant_id\", \"trial_id\",\"time\"])\n",
    ")\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"Renames columns by joining multi-level column names with different delimiters.\"\"\"\n",
    "    # Iterate over all column names\n",
    "    df.columns = [f\"{col[0]}\" if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_correctness_df(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_trials = (df\n",
    "        .query('stimulus_active == True')\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\", \"eye\",\"stand_time\"])\n",
    "        .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.stand_time, None]))\n",
    "        .assign(stimulus_time = lambda x: x[\"stimulus_time\"].ffill())\n",
    "        .assign(saccade_direction = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"sacc_end_x\"] - x[\"sacc_start_x\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"sacc_end_x\"] > x[\"sacc_start_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"sacc_end_x\"] < x[\"sacc_start_x\"])],\n",
    "                                                        ['no_direction',\"right\", \"left\"], default=None))\n",
    "        .assign(saccade_end_area = lambda x: np.select([(x[\"event\"] == 'ESACC') & ( 840 < x[\"sacc_end_x\"]) & (x[\"sacc_end_x\"] < 1080),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (1080 <= x[\"sacc_end_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"sacc_end_x\"] <= 840)],\n",
    "                                                    ['middle',\"right\", \"left\"], default=None))\n",
    "        .assign(is_saccade_correct = lambda x: np.select([(x[\"saccade_direction\"] == 'no_direction')\n",
    "                                                        , (x[\"saccade_end_area\"] == 'middle')\n",
    "                                                        , (x[\"saccade_direction\"] == x[\"saccade_end_area\"]) & (x[\"saccade_direction\"] != x[\"stimulus_side\"]) & (x[\"saccade_end_area\"] != x[\"stimulus_side\"])\n",
    "                                                        , (x[\"saccade_direction\"] == x[\"saccade_end_area\"]) & (x[\"saccade_direction\"] == x[\"stimulus_side\"]) & (x[\"saccade_end_area\"] == x[\"stimulus_side\"])\n",
    "                                                        ],\n",
    "                                                            [None, None, True, False], default=None)) \n",
    "        .assign(is_trial_correct = lambda x: (\n",
    "                x.sort_values(by=[\"participant_id\", \"trial_id\", \"stand_time\"])\n",
    "                .groupby([\"participant_id\", \"trial_id\"])[\"is_saccade_correct\"]\n",
    "                .transform(lambda group: (\n",
    "                    True if not group.dropna().empty and group.dropna().iloc[0] == True else\n",
    "                    False if not group.dropna().empty and group.dropna().iloc[0] == False else\n",
    "                    None\n",
    "                ))\n",
    "            ))\n",
    "    )\n",
    "    return df_trials\n",
    "\n",
    "def get_n_correct_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'n_correct_trials']\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'))\n",
    "     .reset_index()\n",
    "    [[\"experiment\", \"participant_id\", \"n_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def get_prop_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'prop_correct_trials']\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'),\n",
    "          n_trials = ('is_trial_correct', 'count'))\n",
    "     .reset_index()\n",
    "     .assign(prop_correct_trials = lambda x: x[\"n_correct_trials\"] / x[\"n_trials\"])\n",
    "     [[\"experiment\", \"participant_id\", \"prop_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "def get_reaction_time_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df\n",
    "        .query('stimulus_active == True')\n",
    "        .pipe(get_trial_correctness_df)\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\", \"stand_time\"])\n",
    "        .assign(is_saccade_correct = lambda x: np.select([ (x[\"is_saccade_correct\"] == True) ], [True], default=None))\n",
    "        .query(\"is_saccade_correct == True\")\n",
    "        .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .assign(reaction_time = lambda group: group[\"stand_start_time\"] - group[\"stimulus_time\"])\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(reaction_time_avg = ('reaction_time', 'mean'),\n",
    "             reaction_time_std = ('reaction_time', 'std'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pre_calculated_metrics_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment','participant_id', X_FEATURES],\n",
    "    where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "    {'peak_velocity', 'amplitude', 'duration', 'avg_pupil_size'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    features_df = (df.groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(\n",
    "        mean_peak_velocity_sacc = ('peak_velocity', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_amplitude_sacc = ('amplitude', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_sacc = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_fix = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "        mean_pupil_size_fix = ('avg_pupil_size', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )    \n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Finds acceleration features for anti saccade experiment\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with raw samples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "\n",
    "    acceleration = (df.join((df\n",
    "    .groupby([\"experiment\", \"participant_id\", \"trial_id\"])[['x_velocity_left', 'y_velocity_left', 'x_velocity_right', 'y_velocity_right']].shift(1)\n",
    "    .rename(columns={'x_velocity_left': 'x_velocity_left_lagged'\n",
    "            , 'y_velocity_left': 'y_velocity_left_lagged'\n",
    "            , 'x_velocity_right': 'x_velocity_right_lagged'\n",
    "            , 'y_velocity_right': 'y_velocity_right_lagged'}))\n",
    "    ).assign(x_acceleration_left = lambda x: (x[\"x_velocity_left\"] - x[\"x_velocity_left_lagged\"]) / (1/2000),\n",
    "            y_acceleration_left = lambda x: (x[\"y_velocity_left\"] - x[\"y_velocity_left_lagged\"]) / (1/2000),\n",
    "            x_acceleration_right = lambda x: (x[\"x_velocity_right\"] - x[\"x_velocity_right_lagged\"]) / (1/2000),\n",
    "            y_acceleration_right = lambda x: (x[\"y_velocity_right\"] - x[\"y_velocity_right_lagged\"]) / (1/2000))\n",
    "    .assign(total_acceleration_magnitude_left = lambda x: np.sqrt( np.power(x[\"x_acceleration_left\"], 2) + np.power(x[\"y_acceleration_left\"], 2)),\n",
    "            total_acceleration_magnitude_right = lambda x: np.sqrt( np.power(x[\"x_acceleration_right\"], 2) + np.power(x[\"y_acceleration_right\"], 2)))\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg({'total_acceleration_magnitude_left': [np.mean, np.min, np.max, np.median, np.std],\n",
    "        'total_acceleration_magnitude_right': [np.mean, np.min, np.max, np.median, np.std]\n",
    "        })\n",
    "    .reset_index()\n",
    "    .pipe(rename_columns)\n",
    "    )\n",
    "    return acceleration\n",
    "\n",
    "\n",
    "# Eye disconjugacy\n",
    "# Paper: https://www.liebertpub.com/doi/full/10.1089/neu.2014.3687\n",
    "\n",
    "def get_disconjugacy_feature(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    disconjugacy = (df_sample\n",
    "        .sort_values([\"experiment\", \"participant_id\", \"trial_id\", \"time\"])\n",
    "        .query(\"x_left == x_left & x_right == x_right & y_left == y_left & y_right == y_right\") # same as not null\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            x_left_rolling=group[\"x_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            x_right_rolling=group[\"x_right\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_left_rolling=group[\"y_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_right_rolling=group[\"y_right\"].rolling(window=5, min_periods=1).mean()\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            X_diffs = lambda x: ((x[\"x_left_rolling\"] - x[\"x_right_rolling\"]) - 0)**2,\n",
    "            Y_diffs = lambda x: ((x[\"y_left_rolling\"] - x[\"y_right_rolling\"]) - 0)**2\n",
    "        )\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            X_squared_scaled = group[\"X_diffs\"] / group.shape[0],\n",
    "            Y_squared_scaled = group[\"Y_diffs\"] / group.shape[0]\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(\n",
    "            Var_X = (\"X_squared_scaled\", \"sum\"),\n",
    "            Var_Y = (\"Y_squared_scaled\", \"sum\")\n",
    "        )\n",
    "        .assign(\n",
    "            Var_total = lambda x: x[\"Var_X\"] + x[\"Var_Y\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        [[\"experiment\", \"participant_id\", \"Var_total\"]]\n",
    "    )\n",
    "    return disconjugacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_32428/3666569167.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_32428/3666569167.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n"
     ]
    }
   ],
   "source": [
    "def get_anti_saccade_features(df_event: pd.DataFrame, df_sample:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Runs all anti saccade features extractions\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns [\"experiment\", \"participant_id\", X_FEATURES], where X_FEATURES is a collection of features\n",
    "    \"\"\"\n",
    "    \n",
    "    event_feature_functions = [get_pre_calculated_metrics_feature, get_n_correct_trials_feature, get_prop_trials_feature, get_reaction_time_feature]\n",
    "    df_event_features_list = [f(df=df_event) for f in event_feature_functions]\n",
    "    \n",
    "    sample_feature_functions = [get_acceleration_feature, get_disconjugacy_feature]\n",
    "    df_sample_features_list = [f(df=df_sample) for f in sample_feature_functions]\n",
    "    \n",
    "    df_features_list = df_event_features_list + df_sample_features_list\n",
    "    \n",
    "    df_features = reduce(lambda x, y: pd.merge(x, y, on = [\"experiment\", \"participant_id\"]), df_features_list)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "\n",
    "features = get_anti_saccade_features(df_event=df_event, df_sample=df_sample)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join demographic info on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demographic_info() -> pd.DataFrame:\n",
    "    demographics = pd.read_excel(DATA_DIR / \"demographic_info.xlsx\")[[\"ID\", \"Group\"]]\n",
    "\n",
    "    demographics[\"y\"] = (demographics[\"Group\"] == \"PATIENT\").astype(int)\n",
    "    demographics[\"participant_id\"] = demographics[\"ID\"].astype(str)\n",
    "    demographics = demographics[[\"participant_id\", \"y\"]]\n",
    "    return demographics\n",
    "\n",
    "\n",
    "def join_demographic_info_on_features(feature_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    demographics = load_demographic_info()\n",
    "    return pd.merge(feature_df, demographics, how='left', on='participant_id')\n",
    "    \n",
    "data = join_demographic_info_on_features(feature_df=features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = data[\"y\"]\n",
    "X_data = data.drop([\"experiment\", \"participant_id\", \"y\"], axis=1)\n",
    "X_data = X_data[[\"reaction_time_avg\", \"prop_correct_trials\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "columns",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importances",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "95841aa3-8bb2-47e6-bab5-d03950934ff8",
       "rows": [
        [
         "0",
         "reaction_time_avg",
         "0.6866117642359182"
        ],
        [
         "1",
         "prop_correct_trials",
         "0.3133882357640818"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reaction_time_avg</td>\n",
       "      <td>0.686612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prop_correct_trials</td>\n",
       "      <td>0.313388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               columns  importances\n",
       "0    reaction_time_avg     0.686612\n",
       "1  prop_correct_trials     0.313388"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", RandomForestClassifier(max_depth=2))\n",
    "])\n",
    "\n",
    "\n",
    "print(pipe.fit(X_train, y_train).score(X_test, y_test))\n",
    "\n",
    "results=pd.DataFrame()\n",
    "results['columns']=X_train.columns\n",
    "results['importances'] = pipe[\"clf\"].feature_importances_\n",
    "results.sort_values(by='importances',ascending=False,inplace=True)\n",
    "\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
