{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))) + '/src')\n",
    "from config import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "experiment = \"ANTI_SACCADE\"\n",
    "\n",
    "df_event = pd.read_parquet(PREPROCESSED_DIR / f\"{experiment}_events.pq\").reset_index(drop=True)\n",
    "df_sample = (pd.read_parquet(PREPROCESSED_DIR / f'{experiment}_samples.pq')\n",
    " .sort_values([\"experiment\", \"participant_id\", \"trial_id\",\"time\"])\n",
    ")\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"Renames columns by joining multi-level column names with different delimiters.\"\"\"\n",
    "    # Iterate over all column names\n",
    "    df.columns = [f\"{col[0]}\" if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_trial_correctness_df(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    df_trials = (df\n",
    "        .query('stimulus_active == True')\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\",\"time\"])\n",
    "        .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.time, None]))\n",
    "        .assign(stimulus_time = lambda x: x[\"stimulus_time\"].ffill())\n",
    "        .assign(saccade_direction = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"end_x\"] - x[\"start_x\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] > x[\"start_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] < x[\"start_x\"])],\n",
    "                                                        ['no_direction',\"right\", \"left\"], default=None))\n",
    "        .assign(saccade_end_area = lambda x: np.select([(x[\"event\"] == 'ESACC') & ( 840 < x[\"end_x\"]) & (x[\"end_x\"] < 1080),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (1080 <= x[\"end_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] <= 840)],\n",
    "                                                    ['middle',\"right\", \"left\"], default=None))\n",
    "        .assign(is_saccade_correct = lambda x: np.select([(x[\"saccade_direction\"] == 'no_direction')\n",
    "                                                        , (x[\"saccade_end_area\"] == 'middle')\n",
    "                                                        , (x[\"saccade_direction\"] == x[\"saccade_end_area\"]) & (x[\"saccade_direction\"] != x[\"side\"]) & (x[\"saccade_end_area\"] != x[\"side\"])\n",
    "                                                        , (x[\"saccade_direction\"] == x[\"saccade_end_area\"]) & (x[\"saccade_direction\"] == x[\"side\"]) & (x[\"saccade_end_area\"] == x[\"side\"])\n",
    "                                                        ],\n",
    "                                                            [None, None, True, False], default=None)) \n",
    "        .assign(is_trial_correct = lambda x: (\n",
    "                x.sort_values(by=[\"participant_id\", \"trial_id\", \"time\"])\n",
    "                .groupby([\"participant_id\", \"trial_id\"])[\"is_saccade_correct\"]\n",
    "                .transform(lambda group: (\n",
    "                    True if not group.dropna().empty and group.dropna().iloc[0] == True else\n",
    "                    False if not group.dropna().empty and group.dropna().iloc[0] == False else\n",
    "                    None\n",
    "                ))\n",
    "            ))\n",
    "    )\n",
    "    return df_trials\n",
    "\n",
    "\n",
    "def get_n_correct_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'n_correct_trials']\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'))\n",
    "     .reset_index()\n",
    "    [[\"experiment\", \"participant_id\", \"n_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def get_prop_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'prop_correct_trials']\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'),\n",
    "          n_trials = ('is_trial_correct', 'count'))\n",
    "     .reset_index()\n",
    "     .assign(prop_correct_trials = lambda x: x[\"n_correct_trials\"] / x[\"n_trials\"])\n",
    "     [[\"experiment\", \"participant_id\", \"prop_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "def get_reaction_time_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return (df\n",
    "        .query('stimulus_active == True')\n",
    "        .pipe(get_trial_correctness_df)\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\", \"time\"])\n",
    "        .assign(is_saccade_correct = lambda x: np.select([ (x[\"is_saccade_correct\"] == True) ], [True], default=None))\n",
    "        .query(\"is_saccade_correct == True\")\n",
    "        .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .assign(reaction_time = lambda group: group[\"start_time\"] - group[\"stimulus_time\"])\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(reaction_time_avg = ('reaction_time', 'mean'),\n",
    "             reaction_time_std = ('reaction_time', 'std'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_pre_calculated_metrics_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment','participant_id', X_FEATURES],\n",
    "    where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "    {'peak_velocity', 'amplitude', 'duration', 'avg_pupil_size'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    features_df = (df.groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(\n",
    "        mean_peak_velocity_sacc = ('peak_velocity', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_amplitude_sacc = ('amplitude', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_sacc = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_fix = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "        mean_pupil_size_fix = ('avg_pupil_size', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )    \n",
    "    return features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Finds acceleration features for anti saccade experiment\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with raw samples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "\n",
    "    acceleration = (df.join((df\n",
    "    .groupby([\"experiment\", \"participant_id\", \"trial_id\"])[['x_velocity_left', 'y_velocity_left', 'x_velocity_right', 'y_velocity_right']].shift(1)\n",
    "    .rename(columns={'x_velocity_left': 'x_velocity_left_lagged'\n",
    "            , 'y_velocity_left': 'y_velocity_left_lagged'\n",
    "            , 'x_velocity_right': 'x_velocity_right_lagged'\n",
    "            , 'y_velocity_right': 'y_velocity_right_lagged'}))\n",
    "    ).assign(x_acceleration_left = lambda x: (x[\"x_velocity_left\"] - x[\"x_velocity_left_lagged\"]) / (1/2000),\n",
    "            y_acceleration_left = lambda x: (x[\"y_velocity_left\"] - x[\"y_velocity_left_lagged\"]) / (1/2000),\n",
    "            x_acceleration_right = lambda x: (x[\"x_velocity_right\"] - x[\"x_velocity_right_lagged\"]) / (1/2000),\n",
    "            y_acceleration_right = lambda x: (x[\"y_velocity_right\"] - x[\"y_velocity_right_lagged\"]) / (1/2000))\n",
    "    .assign(total_acceleration_magnitude_left = lambda x: np.sqrt( np.power(x[\"x_acceleration_left\"], 2) + np.power(x[\"y_acceleration_left\"], 2)),\n",
    "            total_acceleration_magnitude_right = lambda x: np.sqrt( np.power(x[\"x_acceleration_right\"], 2) + np.power(x[\"y_acceleration_right\"], 2)))\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg({'total_acceleration_magnitude_left': [np.mean, np.min, np.max, np.median, np.std],\n",
    "        'total_acceleration_magnitude_right': [np.mean, np.min, np.max, np.median, np.std]\n",
    "        })\n",
    "    .reset_index()\n",
    "    .pipe(rename_columns)\n",
    "    )\n",
    "    return acceleration\n",
    "\n",
    "\n",
    "# Eye disconjugacy\n",
    "# Paper: https://www.liebertpub.com/doi/full/10.1089/neu.2014.3687\n",
    "\n",
    "def get_disconjugacy_feature(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    disconjugacy = (df_sample\n",
    "        .sort_values([\"experiment\", \"participant_id\", \"trial_id\", \"time\"])\n",
    "        .query(\"x_left == x_left & x_right == x_right & y_left == y_left & y_right == y_right\") # same as not null\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            x_left_rolling=group[\"x_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            x_right_rolling=group[\"x_right\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_left_rolling=group[\"y_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_right_rolling=group[\"y_right\"].rolling(window=5, min_periods=1).mean()\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            X_diffs = lambda x: ((x[\"x_left_rolling\"] - x[\"x_right_rolling\"]) - 0)**2,\n",
    "            Y_diffs = lambda x: ((x[\"y_left_rolling\"] - x[\"y_right_rolling\"]) - 0)**2\n",
    "        )\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            X_squared_scaled = group[\"X_diffs\"] / group.shape[0],\n",
    "            Y_squared_scaled = group[\"Y_diffs\"] / group.shape[0]\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(\n",
    "            Var_X = (\"X_squared_scaled\", \"sum\"),\n",
    "            Var_Y = (\"Y_squared_scaled\", \"sum\")\n",
    "        )\n",
    "        .assign(\n",
    "            Var_total = lambda x: x[\"Var_X\"] + x[\"Var_Y\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        [[\"experiment\", \"participant_id\", \"Var_total\"]]\n",
    "    )\n",
    "    return disconjugacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_62371/3666569167.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_62371/3666569167.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n"
     ]
    }
   ],
   "source": [
    "def get_anti_saccade_features(df_event: pd.DataFrame, df_sample:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Runs all anti saccade features extractions\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns [\"experiment\", \"participant_id\", X_FEATURES], where X_FEATURES is a collection of features\n",
    "    \"\"\"\n",
    "    \n",
    "    event_feature_functions = [get_n_correct_trials_feature, get_prop_trials_feature, get_reaction_time_feature]\n",
    "    df_event_features_list = [f(df=df_event) for f in event_feature_functions]\n",
    "    \n",
    "    sample_feature_functions = [get_acceleration_feature, get_disconjugacy_feature]\n",
    "    df_sample_features_list = [f(df=df_sample) for f in sample_feature_functions]\n",
    "    \n",
    "    df_features_list = df_event_features_list + df_sample_features_list\n",
    "    \n",
    "    df_features = reduce(lambda x, y: pd.merge(x, y, on = [\"experiment\", \"participant_id\"]), df_features_list)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "\n",
    "features = get_anti_saccade_features(df_event=df_event, df_sample=df_sample)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features.to_parquet(FEATURES_DIR / f\"{experiment}_features.pq\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
