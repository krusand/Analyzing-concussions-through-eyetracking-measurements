{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))) + '/src')\n",
    "from config import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "experiment = \"FITTS_LAW\"\n",
    "\n",
    "df_event = pd.read_parquet(PREPROCESSED_DIR / f\"{experiment}_events.pq\").reset_index(drop=True)\n",
    "df_sample = (pd.read_parquet(PREPROCESSED_DIR / f'{experiment}_samples.pq')\n",
    " .sort_values([\"experiment\", \"participant_id\", \"trial_id\",\"time\"])\n",
    ")\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"Renames columns by joining multi-level column names with different delimiters.\"\"\"\n",
    "    # Iterate over all column names\n",
    "    df.columns = [f\"{col[0]}\" if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns.values]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_saccade_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding saccade direction\")\n",
    "    df = (df\n",
    "        .assign(saccade_direction_x = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"end_x\"] - x[\"start_x\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] > x[\"start_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] < x[\"start_x\"])],\n",
    "                                                        ['no_direction',\"right\", \"left\"], default=None))\n",
    "        .assign(saccade_direction_y = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"end_y\"] - x[\"start_y\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_y\"] > x[\"start_y\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_y\"] < x[\"start_y\"])],\n",
    "                                                        ['no_direction',\"up\", \"down\"], default=None))\n",
    "        .assign(saccade_direction = lambda x: np.select([(x[\"saccade_direction_x\"].isin([\"right\", \"left\"])) & (x[\"saccade_direction_y\"].isin([\"up\", \"down\"]))\n",
    "                                                         , (x[\"saccade_direction_x\"].isin([\"right\", \"left\"])) & (x[\"saccade_direction_y\"] == \"no_direction\")\n",
    "                                                         , (x[\"saccade_direction_x\"] == \"no_direction\") & (x[\"saccade_direction_y\"].isin([\"down\", \"up\"]))\n",
    "                                                         , (x[\"saccade_direction_x\"] == \"no_direction\") & (x[\"saccade_direction_y\"] == \"no_direction\")\n",
    "                                                        ]\n",
    "                                                        , [(x[\"saccade_direction_x\"] + \"_\" + x[\"saccade_direction_y\"])\n",
    "                                                         , (x[\"saccade_direction_x\"])\n",
    "                                                         , (x[\"saccade_direction_y\"])\n",
    "                                                         , 'no_direction'\n",
    "                                                        ]\n",
    "                                                        , default=None))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_stimulus_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding stimulus direction\")\n",
    "\n",
    "    MIDDLE_FIXPOINT_X=960\n",
    "    MIDDLE_FIXPOINT_Y=540\n",
    "    \n",
    "    df = (df\n",
    "        .assign(stimulus_direction_x = lambda x: np.select([(x[\"event\"] == 'FIXPOINT') & (np.abs(x[\"stimulus_x\"] - MIDDLE_FIXPOINT_X) < 50),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_x\"] > MIDDLE_FIXPOINT_X),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_x\"] < MIDDLE_FIXPOINT_X)],\n",
    "                                                        [\"middle\", \"right\", \"left\"], default=None))\n",
    "        .assign(stimulus_direction_y = lambda x: np.select([(x[\"event\"] == 'FIXPOINT') & (np.abs(x[\"stimulus_y\"] - MIDDLE_FIXPOINT_Y) < 50),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_y\"] > MIDDLE_FIXPOINT_Y),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_y\"] < MIDDLE_FIXPOINT_Y)],\n",
    "                                                        ['middle',\"up\", \"down\"], default=None))\n",
    "        .assign(stimulus_direction = lambda x: np.select([(x[\"stimulus_direction_x\"].isin([\"right\", \"left\"])) & (x[\"stimulus_direction_y\"].isin([\"up\", \"down\"]))\n",
    "                                                         , (x[\"stimulus_direction_x\"].isin([\"right\", \"left\"])) & (x[\"stimulus_direction_y\"] == \"middle\")\n",
    "                                                         , (x[\"stimulus_direction_x\"] == \"middle\") & (x[\"stimulus_direction_y\"].isin([\"right\", \"left\"]))\n",
    "                                                         , (x[\"stimulus_direction_x\"] == \"middle\") & (x[\"stimulus_direction_y\"] == \"middle\")\n",
    "                                                        ]\n",
    "                                                        , [(x[\"stimulus_direction_x\"] + \"_\" + x[\"stimulus_direction_y\"])\n",
    "                                                         , (x[\"stimulus_direction_x\"])\n",
    "                                                         , (x[\"stimulus_direction_x\"])\n",
    "                                                         , 'middle'\n",
    "                                                        ]\n",
    "                                                        , default=None))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_fixation_area(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding fixation area\")\n",
    "    \n",
    "    MIDDLE_FIXPOINT_X=960\n",
    "    MIDDLE_FIXPOINT_Y=540\n",
    "    \n",
    "    df = (df\n",
    "        .assign(fixation_area_x = lambda x: np.select([(x[\"event\"] == 'EFIX') & (np.abs(x[\"x\"] - MIDDLE_FIXPOINT_X) < 50),\n",
    "                                                        (x[\"event\"] == 'EFIX') & (x[\"x\"] > MIDDLE_FIXPOINT_X),\n",
    "                                                        (x[\"event\"] == 'EFIX') & (x[\"x\"] < MIDDLE_FIXPOINT_X)],\n",
    "                                                        [\"middle\", \"right\", \"left\"], default=None))\n",
    "        .assign(fixation_area_y = lambda x: np.select([(x[\"event\"] == 'EFIX') & (np.abs(x[\"y\"] - MIDDLE_FIXPOINT_Y) < 50),\n",
    "                                                        (x[\"event\"] == 'EFIX') & (x[\"y\"] > MIDDLE_FIXPOINT_Y),\n",
    "                                                        (x[\"event\"] == 'EFIX') & (x[\"y\"] < MIDDLE_FIXPOINT_Y)],\n",
    "                                                        [\"middle\", \"up\", \"down\"], default=None))\n",
    "        .assign(fixation_area = lambda x: np.select([(x[\"fixation_area_x\"].isin([\"right\", \"left\"])) & (x[\"fixation_area_y\"].isin([\"up\", \"down\"]))\n",
    "                                                         , (x[\"fixation_area_x\"].isin([\"right\", \"left\"])) & (x[\"fixation_area_y\"] == \"middle\")\n",
    "                                                         , (x[\"fixation_area_x\"] == \"middle\") & (x[\"fixation_area_y\"].isin([\"right\", \"left\"]))\n",
    "                                                         , (x[\"fixation_area_x\"] == \"middle\") & (x[\"fixation_area_y\"] == \"middle\")\n",
    "                                                        ]\n",
    "                                                        , [(x[\"fixation_area_x\"] + \"_\" + x[\"fixation_area_y\"])\n",
    "                                                         , (x[\"fixation_area_x\"])\n",
    "                                                         , (x[\"fixation_area_x\"])\n",
    "                                                         , 'middle'\n",
    "                                                        ]\n",
    "                                                        , default=None))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_fixations_pr_second(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding fixations pr. second\")\n",
    "    df = (df.query(\"stimulus_active == True\")\n",
    "        .query(\"(eye == 'R') or (eye != eye)\") # right eye or is na\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\",\"time\"])\n",
    "        .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.time, None]))\n",
    "        .assign(stimulus_time = lambda x: x[\"stimulus_time\"].ffill())\n",
    "        .assign(max_event_time = lambda x: (\n",
    "                x.sort_values(by=[\"participant_id\", \"trial_id\", \"time\"])\n",
    "                .groupby([\"participant_id\", \"trial_id\"])[\"time\"]\n",
    "                .transform(lambda group: (\n",
    "                    group.iloc[-1]\n",
    "                ))\n",
    "            ))\n",
    "        .assign(trial_active_duration_seconds = lambda x: (x[\"max_event_time\"] - x[\"stimulus_time\"])/1000)\n",
    "        .query(\"event == 'EFIX'\")\n",
    "        .groupby([\"experiment\", \"participant_id\", \"trial_id\", \"trial_active_duration_seconds\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"n_fixations\")\n",
    "        .assign(fixations_per_second=lambda x: x[\"n_fixations\"] / x[\"trial_active_duration_seconds\"])\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(avg_fixations_pr_second = ('fixations_per_second', 'mean'),\n",
    "             std_fixations_pr_second = ('fixations_per_second', 'std'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_pre_calculated_metrics_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment','participant_id', X_FEATURES],\n",
    "    where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "    {'peak_velocity', 'amplitude', 'duration', 'avg_pupil_size'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    features_df = (df.groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(\n",
    "        mean_peak_velocity_sacc = ('peak_velocity', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_amplitude_sacc = ('amplitude', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_sacc = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_fix = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "        mean_pupil_size_fix = ('avg_pupil_size', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )    \n",
    "    return features_df\n",
    "\n",
    "\n",
    "\n",
    "def add_nearest_fixation_overshoot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding fixation overshoot\")\n",
    "    result = []\n",
    "    \n",
    "    grouped_df = df.sort_values(['participant_id', 'trial_id', 'time']).groupby(['participant_id', 'trial_id'])\n",
    "    \n",
    "    for (participant, trial), group in tqdm(grouped_df):\n",
    "        group = group.copy()\n",
    "        \n",
    "        stimulus = group.query(\"event == 'FIXPOINT'\")\n",
    "        \n",
    "        stimulus_coords = [\n",
    "            (stimulus.iloc[0][\"stimulus_x\"], stimulus.iloc[0][\"stimulus_y\"]),\n",
    "            (stimulus.iloc[1][\"stimulus_x\"], stimulus.iloc[1][\"stimulus_y\"])\n",
    "        ]\n",
    "        \n",
    "        def compute_distances(row):\n",
    "            for i, (sx, sy) in enumerate(stimulus_coords, start=1):\n",
    "                row[f\"distance_to_stimulus_{i}\"] = np.sqrt(np.power((row[\"x\"] - sx),2) + np.power((row[\"y\"] - sy),2))\n",
    "            return row\n",
    "        \n",
    "        group = group.apply(compute_distances, axis=1)\n",
    "        result.append(group)\n",
    "        \n",
    "    df_with_distances = pd.concat(result, ignore_index=True)\n",
    "\n",
    "    df_with_distances['distance_to_nearest_stimulus'] = df_with_distances[['distance_to_stimulus_1','distance_to_stimulus_2']].min(axis=1)\n",
    "\n",
    "    return df_with_distances\n",
    "\n",
    "\n",
    "def get_fixation_overshoot(df: pd.DataFrame) -> pd.DataFrame:\n",
    "            \n",
    "    df = (df\n",
    "    .query(\"stimulus_active == True\")\n",
    "    .query(\"(eye == 'R') or (eye != eye)\") # right eye or is na\n",
    "    .sort_values(by=[\"participant_id\", \"trial_id\",\"time\"])\n",
    "    .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.time, None]))\n",
    "    .assign(stimulus_time = lambda x: x[\"stimulus_time\"].ffill())\n",
    "    .pipe(add_saccade_direction)\n",
    "    .pipe(add_stimulus_direction)\n",
    "    .pipe(add_fixation_area) \n",
    "    .pipe(add_nearest_fixation_overshoot)\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(avg_fixation_overshoot = ('distance_to_nearest_stimulus', 'mean'),\n",
    "         std_fixation_overshoot = ('distance_to_nearest_stimulus', 'std'))\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Finds acceleration features for anti saccade experiment\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with raw samples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting acceleration\")\n",
    "    acceleration = (df.join((df\n",
    "    .groupby([\"experiment\", \"participant_id\", \"trial_id\"])[['x_velocity_left', 'y_velocity_left', 'x_velocity_right', 'y_velocity_right']].shift(1)\n",
    "    .rename(columns={'x_velocity_left': 'x_velocity_left_lagged'\n",
    "            , 'y_velocity_left': 'y_velocity_left_lagged'\n",
    "            , 'x_velocity_right': 'x_velocity_right_lagged'\n",
    "            , 'y_velocity_right': 'y_velocity_right_lagged'}))\n",
    "    ).assign(x_acceleration_left = lambda x: (x[\"x_velocity_left\"] - x[\"x_velocity_left_lagged\"]) / (1/2000),\n",
    "            y_acceleration_left = lambda x: (x[\"y_velocity_left\"] - x[\"y_velocity_left_lagged\"]) / (1/2000),\n",
    "            x_acceleration_right = lambda x: (x[\"x_velocity_right\"] - x[\"x_velocity_right_lagged\"]) / (1/2000),\n",
    "            y_acceleration_right = lambda x: (x[\"y_velocity_right\"] - x[\"y_velocity_right_lagged\"]) / (1/2000))\n",
    "    .assign(total_acceleration_magnitude_left = lambda x: np.sqrt( np.power(x[\"x_acceleration_left\"], 2) + np.power(x[\"y_acceleration_left\"], 2)),\n",
    "            total_acceleration_magnitude_right = lambda x: np.sqrt( np.power(x[\"x_acceleration_right\"], 2) + np.power(x[\"y_acceleration_right\"], 2)))\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg({'total_acceleration_magnitude_left': [np.mean, np.min, np.max, np.median, np.std],\n",
    "        'total_acceleration_magnitude_right': [np.mean, np.min, np.max, np.median, np.std]\n",
    "        })\n",
    "    .reset_index()\n",
    "    .pipe(rename_columns)\n",
    "    )\n",
    "    return acceleration\n",
    "\n",
    "\n",
    "# Eye disconjugacy\n",
    "# Paper: https://www.liebertpub.com/doi/full/10.1089/neu.2014.3687\n",
    "\n",
    "def get_disconjugacy_feature(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Extracting disconjugacy\")\n",
    "    disconjugacy = (df_sample\n",
    "        .sort_values([\"experiment\", \"participant_id\", \"trial_id\", \"time\"])\n",
    "        .query(\"x_left == x_left & x_right == x_right & y_left == y_left & y_right == y_right\") # same as not null\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            x_left_rolling=group[\"x_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            x_right_rolling=group[\"x_right\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_left_rolling=group[\"y_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_right_rolling=group[\"y_right\"].rolling(window=5, min_periods=1).mean()\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            X_diffs = lambda x: ((x[\"x_left_rolling\"] - x[\"x_right_rolling\"]) - 0)**2,\n",
    "            Y_diffs = lambda x: ((x[\"y_left_rolling\"] - x[\"y_right_rolling\"]) - 0)**2\n",
    "        )\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            X_squared_scaled = group[\"X_diffs\"] / group.shape[0],\n",
    "            Y_squared_scaled = group[\"Y_diffs\"] / group.shape[0]\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(\n",
    "            Var_X = (\"X_squared_scaled\", \"sum\"),\n",
    "            Var_Y = (\"Y_squared_scaled\", \"sum\")\n",
    "        )\n",
    "        .assign(\n",
    "            Var_total = lambda x: x[\"Var_X\"] + x[\"Var_Y\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        [[\"experiment\", \"participant_id\", \"Var_total\"]]\n",
    "    )\n",
    "    return disconjugacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 15:22:45,422 - INFO - 3593954449.get_fitts_law_features:10 - Starting f\n",
      "2025-04-16 15:22:45,572 - INFO - 62884451.add_saccade_direction:2 - Adding saccade direction\n",
      "2025-04-16 15:22:45,679 - INFO - 62884451.add_stimulus_direction:28 - Adding stimulus direction\n",
      "2025-04-16 15:22:45,755 - INFO - 62884451.add_fixation_area:60 - Adding fixation area\n",
      "2025-04-16 15:22:45,874 - INFO - 62884451.add_nearest_fixation_overshoot:141 - Adding fixation overshoot\n",
      "100%|██████████| 1670/1670 [00:31<00:00, 53.15it/s]\n",
      "2025-04-16 15:23:17,866 - INFO - 62884451.get_fixations_pr_second:92 - Adding fixations pr. second\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_72337/3666569167.py:43: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_72337/3666569167.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n"
     ]
    }
   ],
   "source": [
    "def get_fitts_law_features(df_event: pd.DataFrame, df_sample:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Runs all fitts law features extractions\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns [\"experiment\", \"participant_id\", X_FEATURES], where X_FEATURES is a collection of features\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting fitts law feature extraction\")\n",
    "    \n",
    "    logging.info(\"Starting event feature extraction\")\n",
    "    event_feature_functions = [get_fixation_overshoot, get_fixations_pr_second, get_pre_calculated_metrics_feature]\n",
    "    df_event_features_list = [f(df=df_event) for f in event_feature_functions]\n",
    "    \n",
    "    logging.info(\"Starting sample feature extraction\")\n",
    "    sample_feature_functions = [get_acceleration_feature, get_disconjugacy_feature]\n",
    "    df_sample_features_list = [f(df=df_sample) for f in sample_feature_functions]\n",
    "    \n",
    "    df_features_list = df_event_features_list + df_sample_features_list\n",
    "    \n",
    "    df_features = reduce(lambda x, y: pd.merge(x, y, on = [\"experiment\", \"participant_id\"]), df_features_list)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "\n",
    "features = get_fitts_law_features(df_event=df_event, df_sample=df_sample)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_parquet(FEATURES_DIR / f\"{experiment}_features.pq\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
