{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))) + '/src')\n",
    "from config import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from tqdm import tqdm\n",
    "\n",
    "experiment = \"KING_DEVICK\"\n",
    "\n",
    "df_event = pd.read_parquet(PREPROCESSED_DIR / f\"{experiment}_events.pq\").reset_index(drop=True)\n",
    "df_sample = (pd.read_parquet(PREPROCESSED_DIR / f'{experiment}_samples.pq')\n",
    " .sort_values([\"experiment\", \"participant_id\", \"trial_id\",\"time\"])\n",
    ")\n",
    "\n",
    "def rename_columns(df):\n",
    "    \"\"\"Renames columns by joining multi-level column names with different delimiters.\"\"\"\n",
    "    # Iterate over all column names\n",
    "    df.columns = [f\"{col[0]}\" if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns.values]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_mistakes_pr_trial(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (df\n",
    "          .query(\"event == 'TRIAL_VAR_DATA'\")\n",
    "          .groupby([\"experiment\", \"participant_id\"])\n",
    "          .agg(avg_mistakes_pr_trial = ('marks', 'mean'))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return df\n",
    "    \n",
    "def get_avg_time_elapsed_pr_trial(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = (df\n",
    "          .query(\"event == 'TRIAL_VAR_DATA'\")\n",
    "          .groupby([\"experiment\", \"participant_id\"])\n",
    "          .agg(avg_time_elapsed_pr_trial = ('time_elapsed', 'mean'))\n",
    "          .reset_index()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def get_pre_calculated_metrics_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment','participant_id', X_FEATURES],\n",
    "    where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "    {'peak_velocity', 'amplitude', 'duration', 'avg_pupil_size'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    features_df = (df.groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(\n",
    "        mean_peak_velocity_sacc = ('peak_velocity', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_amplitude_sacc = ('amplitude', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_sacc = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_fix = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "        mean_pupil_size_fix = ('avg_pupil_size', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )    \n",
    "    return features_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Finds acceleration features for anti saccade experiment\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with raw samples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting acceleration\")\n",
    "    acceleration = (df.join((df\n",
    "    .groupby([\"experiment\", \"participant_id\", \"trial_id\"])[['x_velocity_left', 'y_velocity_left', 'x_velocity_right', 'y_velocity_right']].shift(1)\n",
    "    .rename(columns={'x_velocity_left': 'x_velocity_left_lagged'\n",
    "            , 'y_velocity_left': 'y_velocity_left_lagged'\n",
    "            , 'x_velocity_right': 'x_velocity_right_lagged'\n",
    "            , 'y_velocity_right': 'y_velocity_right_lagged'}))\n",
    "    ).assign(x_acceleration_left = lambda x: (x[\"x_velocity_left\"] - x[\"x_velocity_left_lagged\"]) / (1/2000),\n",
    "            y_acceleration_left = lambda x: (x[\"y_velocity_left\"] - x[\"y_velocity_left_lagged\"]) / (1/2000),\n",
    "            x_acceleration_right = lambda x: (x[\"x_velocity_right\"] - x[\"x_velocity_right_lagged\"]) / (1/2000),\n",
    "            y_acceleration_right = lambda x: (x[\"y_velocity_right\"] - x[\"y_velocity_right_lagged\"]) / (1/2000))\n",
    "    .assign(total_acceleration_magnitude_left = lambda x: np.sqrt( np.power(x[\"x_acceleration_left\"], 2) + np.power(x[\"y_acceleration_left\"], 2)),\n",
    "            total_acceleration_magnitude_right = lambda x: np.sqrt( np.power(x[\"x_acceleration_right\"], 2) + np.power(x[\"y_acceleration_right\"], 2)))\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg({'total_acceleration_magnitude_left': [np.mean, np.min, np.max, np.median, np.std],\n",
    "        'total_acceleration_magnitude_right': [np.mean, np.min, np.max, np.median, np.std]\n",
    "        })\n",
    "    .reset_index()\n",
    "    .pipe(rename_columns)\n",
    "    )\n",
    "    return acceleration\n",
    "\n",
    "\n",
    "# Eye disconjugacy\n",
    "# Paper: https://www.liebertpub.com/doi/full/10.1089/neu.2014.3687\n",
    "\n",
    "def get_disconjugacy_feature(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Extracting disconjugacy\")\n",
    "    disconjugacy = (df\n",
    "        .sort_values([\"experiment\", \"participant_id\", \"trial_id\", \"time\"])\n",
    "        .query(\"x_left == x_left & x_right == x_right & y_left == y_left & y_right == y_right\") # same as not null\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            x_left_rolling=group[\"x_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            x_right_rolling=group[\"x_right\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_left_rolling=group[\"y_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_right_rolling=group[\"y_right\"].rolling(window=5, min_periods=1).mean()\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            X_diffs = lambda x: ((x[\"x_left_rolling\"] - x[\"x_right_rolling\"]) - 0)**2,\n",
    "            Y_diffs = lambda x: ((x[\"y_left_rolling\"] - x[\"y_right_rolling\"]) - 0)**2\n",
    "        )\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            X_squared_scaled = group[\"X_diffs\"] / group.shape[0],\n",
    "            Y_squared_scaled = group[\"Y_diffs\"] / group.shape[0]\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(\n",
    "            Var_X = (\"X_squared_scaled\", \"sum\"),\n",
    "            Var_Y = (\"Y_squared_scaled\", \"sum\")\n",
    "        )\n",
    "        .assign(\n",
    "            Var_total = lambda x: x[\"Var_X\"] + x[\"Var_Y\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        [[\"experiment\", \"participant_id\", \"Var_total\"]]\n",
    "    )\n",
    "    return disconjugacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 16:25:14,236 - INFO - 2866491546.get_king_devick_features:10 - Starting fitts law feature extraction\n",
      "2025-04-16 16:25:14,238 - INFO - 2866491546.get_king_devick_features:12 - Starting event feature extraction\n",
      "2025-04-16 16:25:14,456 - INFO - 2866491546.get_king_devick_features:16 - Starting sample feature extraction\n",
      "2025-04-16 16:25:14,456 - INFO - 615019999.get_acceleration_feature:12 - Extracting acceleration\n",
      "2025-04-16 16:25:30,490 - INFO - 615019999.get_disconjugacy_feature:39 - Extracting disconjugacy\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_74155/615019999.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_74155/615019999.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n"
     ]
    }
   ],
   "source": [
    "def get_king_devick_features(df_event: pd.DataFrame, df_sample:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Runs all king devick features extractions\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns [\"experiment\", \"participant_id\", X_FEATURES], where X_FEATURES is a collection of features\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting fitts law feature extraction\")\n",
    "    \n",
    "    logging.info(\"Starting event feature extraction\")\n",
    "    event_feature_functions = [get_avg_mistakes_pr_trial, get_avg_time_elapsed_pr_trial, get_pre_calculated_metrics_feature]\n",
    "    df_event_features_list = [f(df=df_event) for f in event_feature_functions]\n",
    "    \n",
    "    logging.info(\"Starting sample feature extraction\")\n",
    "    sample_feature_functions = [get_acceleration_feature, get_disconjugacy_feature]\n",
    "    df_sample_features_list = [f(df=df_sample) for f in sample_feature_functions]\n",
    "    \n",
    "    df_features_list = df_event_features_list + df_sample_features_list\n",
    "    \n",
    "    df_features = reduce(lambda x, y: pd.merge(x, y, on = [\"experiment\", \"participant_id\"]), df_features_list)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "\n",
    "features = get_king_devick_features(df_event=df_event, df_sample=df_sample)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_parquet(FEATURES_DIR / f\"{experiment}_features.pq\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
