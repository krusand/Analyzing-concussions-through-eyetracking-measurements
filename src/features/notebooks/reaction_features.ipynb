{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(''))) + '/src')\n",
    "from config import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import reduce\n",
    "\n",
    "experiment = \"REACTION\"\n",
    "\n",
    "df_event = pd.read_parquet(PREPROCESSED_DIR / f\"{experiment}_events.pq\")\n",
    "df_sample = (pd.read_parquet(PREPROCESSED_DIR / f'{experiment}_samples.pq')\n",
    " .sort_values([\"experiment\", \"participant_id\", \"trial_id\",\"time\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rename_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Renames columns by joining multi-level column names with different delimiters.\"\"\"\n",
    "    # Iterate over all column names\n",
    "    df.columns = [f\"{col[0]}\" if col[1] == '' else f\"{col[0]}_{col[1]}\" for col in df.columns.values]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_pre_calculated_metrics_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment','participant_id', X_FEATURES],\n",
    "    where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "    {'peak_velocity', 'amplitude', 'duration', 'avg_pupil_size'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting precalculated metrics\")\n",
    "    features_df = (df\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg(\n",
    "        mean_peak_velocity_sacc = ('peak_velocity', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_amplitude_sacc = ('amplitude', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_sacc = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'ESACC'].mean()),\n",
    "        mean_duration_fix = ('duration', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "        mean_pupil_size_fix = ('avg_pupil_size', lambda x: x[df.loc[x.index, 'event'] == 'EFIX'].mean()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )    \n",
    "    return features_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_saccade_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding saccade direction\")\n",
    "    df = (df\n",
    "        .assign(saccade_direction_x = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"end_x\"] - x[\"start_x\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] > x[\"start_x\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_x\"] < x[\"start_x\"])],\n",
    "                                                        ['no_direction',\"right\", \"left\"], default=None))\n",
    "        .assign(saccade_direction_y = lambda x: np.select([(x[\"event\"] == 'ESACC') & (np.abs(x[\"end_y\"] - x[\"start_y\"]) < 50),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_y\"] > x[\"start_y\"]),\n",
    "                                                        (x[\"event\"] == 'ESACC') & (x[\"end_y\"] < x[\"start_y\"])],\n",
    "                                                        ['no_direction',\"up\", \"down\"], default=None))\n",
    "        .assign(saccade_direction = lambda x: np.select([(x[\"saccade_direction_x\"].isin([\"right\", \"left\"])) & (x[\"saccade_direction_y\"].isin([\"up\", \"down\"]))\n",
    "                                                         , (x[\"saccade_direction_x\"].isin([\"right\", \"left\"])) & (x[\"saccade_direction_y\"] == \"no_direction\")\n",
    "                                                         , (x[\"saccade_direction_x\"] == \"no_direction\") & (x[\"saccade_direction_y\"].isin([\"down\", \"up\"]))\n",
    "                                                         , (x[\"saccade_direction_x\"] == \"no_direction\") & (x[\"saccade_direction_y\"] == \"no_direction\")\n",
    "                                                        ]\n",
    "                                                        , [(x[\"saccade_direction_x\"] + \"_\" + x[\"saccade_direction_y\"])\n",
    "                                                         , (x[\"saccade_direction_x\"])\n",
    "                                                         , (x[\"saccade_direction_y\"])\n",
    "                                                         , 'no_direction'\n",
    "                                                        ]\n",
    "                                                        , default=None))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_stimulus_direction(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Adding stimulus direction\")\n",
    "\n",
    "    MIDDLE_FIXPOINT_X=960\n",
    "    MIDDLE_FIXPOINT_Y=540\n",
    "    \n",
    "    df = (df\n",
    "        .assign(stimulus_direction_x = lambda x: np.select([(x[\"event\"] == 'FIXPOINT') & (np.abs(x[\"stimulus_x\"] - MIDDLE_FIXPOINT_X) < 50),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_x\"] > MIDDLE_FIXPOINT_X),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_x\"] < MIDDLE_FIXPOINT_X)],\n",
    "                                                        [\"middle\", \"right\", \"left\"], default=None))\n",
    "        .assign(stimulus_direction_y = lambda x: np.select([(x[\"event\"] == 'FIXPOINT') & (np.abs(x[\"stimulus_y\"] - MIDDLE_FIXPOINT_Y) < 50),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_y\"] > MIDDLE_FIXPOINT_Y),\n",
    "                                                        (x[\"event\"] == 'FIXPOINT') & (x[\"stimulus_y\"] < MIDDLE_FIXPOINT_Y)],\n",
    "                                                        ['middle',\"up\", \"down\"], default=None))\n",
    "        .assign(stimulus_direction = lambda x: np.select([(x[\"stimulus_direction_x\"].isin([\"right\", \"left\"])) & (x[\"stimulus_direction_y\"].isin([\"up\", \"down\"]))\n",
    "                                                         , (x[\"stimulus_direction_x\"].isin([\"right\", \"left\"])) & (x[\"stimulus_direction_y\"] == \"middle\")\n",
    "                                                         , (x[\"stimulus_direction_x\"] == \"middle\") & (x[\"stimulus_direction_y\"].isin([\"right\", \"left\"]))\n",
    "                                                         , (x[\"stimulus_direction_x\"] == \"middle\") & (x[\"stimulus_direction_y\"] == \"middle\")\n",
    "                                                        ]\n",
    "                                                        , [(x[\"stimulus_direction_x\"] + \"_\" + x[\"stimulus_direction_y\"])\n",
    "                                                         , (x[\"stimulus_direction_x\"])\n",
    "                                                         , (x[\"stimulus_direction_x\"])\n",
    "                                                         , 'middle'\n",
    "                                                        ]\n",
    "                                                        , default=None)).ffill()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_trial_correctness_df(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Extracting trial correctness\")\n",
    "\n",
    "    df_trials = (df_event\n",
    "            .query('stimulus_active == True')\n",
    "            .sort_values(by=[\"participant_id\", \"trial_id\",\"time\"])\n",
    "            .assign(stimulus_time = lambda x: np.select([x.event == \"FIXPOINT\", x.event != \"FIXPOINT\"], [x.time, None]))\n",
    "            .assign(stimulus_time = lambda x: x[\"stimulus_time\"].ffill())\n",
    "            .pipe(add_stimulus_direction)\n",
    "            .pipe(add_saccade_direction)\n",
    "            .assign(is_saccade_correct = lambda x: np.select([ (x[\"saccade_direction\"].notna()) & (x[\"saccade_direction\"] == 'no_direction')\n",
    "                                                            , (x[\"saccade_direction\"].notna()) & (x[\"saccade_direction\"] == x[\"stimulus_direction\"])\n",
    "                                                            , (x[\"saccade_direction\"].notna()) & (x[\"saccade_direction\"] != x[\"stimulus_direction\"])\n",
    "                                                            ],\n",
    "                                                            [False, True, False], default=None)) \n",
    "            .assign(is_trial_correct = lambda x: (\n",
    "                    x.sort_values(by=[\"participant_id\", \"trial_id\", \"time\"])\n",
    "                    .groupby([\"participant_id\", \"trial_id\"])[\"is_saccade_correct\"]\n",
    "                    .transform(lambda group: (\n",
    "                        True if not group.dropna().empty and group.dropna().iloc[0] == True else\n",
    "                        False if not group.dropna().empty and group.dropna().iloc[0] == False else\n",
    "                        None\n",
    "                    ))\n",
    "                ))\n",
    "    )\n",
    "    return df_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_n_correct_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'n_correct_trials']\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting n correct trials\")\n",
    "\n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'))\n",
    "     .reset_index()\n",
    "    [[\"experiment\", \"participant_id\", \"n_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "\n",
    "def get_prop_trials_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns pd.Dataframe with columns ['experiment', 'participant_id', 'prop_correct_trials']\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting prop correct trials\")\n",
    "\n",
    "    feature_df = (df\n",
    "     .pipe(get_trial_correctness_df)\n",
    "     .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "     .agg(is_trial_correct = ('is_trial_correct', 'min')) \n",
    "     .reset_index()\n",
    "     .groupby([\"experiment\", \"participant_id\"])\n",
    "     .agg(n_correct_trials = ('is_trial_correct', 'sum'),\n",
    "          n_trials = ('is_trial_correct', 'count'))\n",
    "     .reset_index()\n",
    "     .assign(prop_correct_trials = lambda x: x[\"n_correct_trials\"] / x[\"n_trials\"])\n",
    "     [[\"experiment\", \"participant_id\", \"prop_correct_trials\"]]\n",
    "    )\n",
    "    \n",
    "    return feature_df\n",
    "\n",
    "def get_reaction_time_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Extracting reaction time\")\n",
    "\n",
    "    return (df\n",
    "        .query('stimulus_active == True')\n",
    "        .pipe(get_trial_correctness_df)\n",
    "        .sort_values(by=[\"participant_id\", \"trial_id\", \"time\"])\n",
    "        .assign(is_saccade_correct = lambda x: np.select([ (x[\"is_saccade_correct\"] == True) ], [True], default=None))\n",
    "        .query(\"is_saccade_correct == True\")\n",
    "        .groupby([\"experiment\",\"participant_id\", \"trial_id\"])\n",
    "        .first()\n",
    "        .reset_index()\n",
    "        .assign(reaction_time = lambda group: group[\"start_time\"] - group[\"stimulus_time\"])\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(reaction_time_avg = ('reaction_time', 'mean'),\n",
    "             reaction_time_std = ('reaction_time', 'std'))\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acceleration_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Finds acceleration features for anti saccade experiment\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with raw samples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting acceleration\")\n",
    "    acceleration = (df.join((df\n",
    "    .groupby([\"experiment\", \"participant_id\", \"trial_id\"])[['x_velocity_left', 'y_velocity_left', 'x_velocity_right', 'y_velocity_right']].shift(1)\n",
    "    .rename(columns={'x_velocity_left': 'x_velocity_left_lagged'\n",
    "            , 'y_velocity_left': 'y_velocity_left_lagged'\n",
    "            , 'x_velocity_right': 'x_velocity_right_lagged'\n",
    "            , 'y_velocity_right': 'y_velocity_right_lagged'}))\n",
    "    ).assign(x_acceleration_left = lambda x: (x[\"x_velocity_left\"] - x[\"x_velocity_left_lagged\"]) / (1/2000),\n",
    "            y_acceleration_left = lambda x: (x[\"y_velocity_left\"] - x[\"y_velocity_left_lagged\"]) / (1/2000),\n",
    "            x_acceleration_right = lambda x: (x[\"x_velocity_right\"] - x[\"x_velocity_right_lagged\"]) / (1/2000),\n",
    "            y_acceleration_right = lambda x: (x[\"y_velocity_right\"] - x[\"y_velocity_right_lagged\"]) / (1/2000))\n",
    "    .assign(total_acceleration_magnitude_left = lambda x: np.sqrt( np.power(x[\"x_acceleration_left\"], 2) + np.power(x[\"y_acceleration_left\"], 2)),\n",
    "            total_acceleration_magnitude_right = lambda x: np.sqrt( np.power(x[\"x_acceleration_right\"], 2) + np.power(x[\"y_acceleration_right\"], 2)))\n",
    "    .groupby([\"experiment\", \"participant_id\"])\n",
    "    .agg({'total_acceleration_magnitude_left': [np.mean, np.min, np.max, np.median, np.std],\n",
    "        'total_acceleration_magnitude_right': [np.mean, np.min, np.max, np.median, np.std]\n",
    "        })\n",
    "    .reset_index()\n",
    "    .pipe(rename_columns)\n",
    "    )\n",
    "    return acceleration\n",
    "\n",
    "\n",
    "# Eye disconjugacy\n",
    "# Paper: https://www.liebertpub.com/doi/full/10.1089/neu.2014.3687\n",
    "\n",
    "def get_disconjugacy_feature(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    logging.info(\"Extracting disconjugacy\")\n",
    "    disconjugacy = (df\n",
    "        .sort_values([\"experiment\", \"participant_id\", \"trial_id\", \"time\"])\n",
    "        .query(\"x_left == x_left & x_right == x_right & y_left == y_left & y_right == y_right\") # same as not null\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            x_left_rolling=group[\"x_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            x_right_rolling=group[\"x_right\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_left_rolling=group[\"y_left\"].rolling(window=5, min_periods=1).mean(),\n",
    "            y_right_rolling=group[\"y_right\"].rolling(window=5, min_periods=1).mean()\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .assign(\n",
    "            X_diffs = lambda x: ((x[\"x_left_rolling\"] - x[\"x_right_rolling\"]) - 0)**2,\n",
    "            Y_diffs = lambda x: ((x[\"y_left_rolling\"] - x[\"y_right_rolling\"]) - 0)**2\n",
    "        )\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .apply(lambda group: group.assign(\n",
    "            X_squared_scaled = group[\"X_diffs\"] / group.shape[0],\n",
    "            Y_squared_scaled = group[\"Y_diffs\"] / group.shape[0]\n",
    "        ))\n",
    "        .reset_index(drop=True)\n",
    "        .groupby([\"experiment\", \"participant_id\"])\n",
    "        .agg(\n",
    "            Var_X = (\"X_squared_scaled\", \"sum\"),\n",
    "            Var_Y = (\"Y_squared_scaled\", \"sum\")\n",
    "        )\n",
    "        .assign(\n",
    "            Var_total = lambda x: x[\"Var_X\"] + x[\"Var_Y\"]\n",
    "        )\n",
    "        .reset_index()\n",
    "        [[\"experiment\", \"participant_id\", \"Var_total\"]]\n",
    "    )\n",
    "    return disconjugacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 11:39:09,648 - INFO - 417567659.get_reaction_features:10 - Extracting reaction features\n",
      "2025-04-16 11:39:09,649 - INFO - 2577773216.get_n_correct_trials_feature:5 - Extracting n correct trials\n",
      "2025-04-16 11:39:09,650 - INFO - 494265785.get_trial_correctness_df:57 - Extracting trial correctness\n",
      "2025-04-16 11:39:09,738 - INFO - 494265785.add_stimulus_direction:28 - Adding stimulus direction\n",
      "2025-04-16 11:39:09,785 - INFO - 494265785.add_saccade_direction:2 - Adding saccade direction\n",
      "2025-04-16 11:39:10,167 - INFO - 2577773216.get_prop_trials_feature:25 - Extracting prop correct trials\n",
      "2025-04-16 11:39:10,167 - INFO - 494265785.get_trial_correctness_df:57 - Extracting trial correctness\n",
      "2025-04-16 11:39:10,192 - INFO - 494265785.add_stimulus_direction:28 - Adding stimulus direction\n",
      "2025-04-16 11:39:10,236 - INFO - 494265785.add_saccade_direction:2 - Adding saccade direction\n",
      "2025-04-16 11:39:10,633 - INFO - 2577773216.get_reaction_time_feature:43 - Extracting reaction time\n",
      "2025-04-16 11:39:10,643 - INFO - 494265785.get_trial_correctness_df:57 - Extracting trial correctness\n",
      "2025-04-16 11:39:10,669 - INFO - 494265785.add_stimulus_direction:28 - Adding stimulus direction\n",
      "2025-04-16 11:39:10,712 - INFO - 494265785.add_saccade_direction:2 - Adding saccade direction\n",
      "2025-04-16 11:39:11,084 - INFO - 654501450.get_acceleration_feature:12 - Extracting acceleration\n",
      "2025-04-16 11:42:13,982 - INFO - 654501450.get_disconjugacy_feature:39 - Extracting disconjugacy\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_64680/654501450.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n",
      "/var/folders/v0/l_dtghc15651j6_9p3clc_r00000gt/T/ipykernel_64680/654501450.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda group: group.assign(\n"
     ]
    }
   ],
   "source": [
    "def get_reaction_features(df_event: pd.DataFrame, df_sample:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Runs all reaction feature extractions\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The preprocessed dataframe\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Dataframe with columns [\"experiment\", \"participant_id\", X_FEATURES], where X_FEATURES is a collection of features\n",
    "    \"\"\"\n",
    "    logging.info(\"Extracting reaction features\")\n",
    "    event_feature_functions = [get_n_correct_trials_feature, get_prop_trials_feature, get_reaction_time_feature]\n",
    "    df_event_features_list = [f(df=df_event) for f in event_feature_functions]\n",
    "    \n",
    "    sample_feature_functions = [get_acceleration_feature, get_disconjugacy_feature]\n",
    "    df_sample_features_list = [f(df=df_sample) for f in sample_feature_functions]\n",
    "    \n",
    "    df_features_list = df_event_features_list + df_sample_features_list\n",
    "    \n",
    "    df_features = reduce(lambda x, y: pd.merge(x, y, on = [\"experiment\", \"participant_id\"]), df_features_list)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "\n",
    "features = get_reaction_features(df_event=df_event, df_sample=df_sample)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_parquet(FEATURES_DIR / f\"{experiment}_features.pq\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much faster is polars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "def get_acceleration_feature_pl(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Finds acceleration features for anti saccade experiment using Polars.\n",
    "\n",
    "    Args:\n",
    "        df (pl.DataFrame): Dataframe with raw samples.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: Dataframe with columns ['experiment','participant_id', X_FEATURES]\n",
    "        where X_FEATURES is a collection of features found by the following cartesian product:\n",
    "        {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} \n",
    "        x {mean, min, max, median, std}\n",
    "    \"\"\"\n",
    "    logging.info(\"Started acceleration feature\")\n",
    "\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"x_velocity_left\").shift(1).over([\"experiment\", \"participant_id\", \"trial_id\"]).alias(\"x_velocity_left_lagged\"),\n",
    "        pl.col(\"y_velocity_left\").shift(1).over([\"experiment\", \"participant_id\", \"trial_id\"]).alias(\"y_velocity_left_lagged\"),\n",
    "        pl.col(\"x_velocity_right\").shift(1).over([\"experiment\", \"participant_id\", \"trial_id\"]).alias(\"x_velocity_right_lagged\"),\n",
    "        pl.col(\"y_velocity_right\").shift(1).over([\"experiment\", \"participant_id\", \"trial_id\"]).alias(\"y_velocity_right_lagged\")\n",
    "    ]).with_columns([\n",
    "        ((pl.col(\"x_velocity_left\") - pl.col(\"x_velocity_left_lagged\")) * 2000).alias(\"x_acceleration_left\"),\n",
    "        ((pl.col(\"y_velocity_left\") - pl.col(\"y_velocity_left_lagged\")) * 2000).alias(\"y_acceleration_left\"),\n",
    "        ((pl.col(\"x_velocity_right\") - pl.col(\"x_velocity_right_lagged\")) * 2000).alias(\"x_acceleration_right\"),\n",
    "        ((pl.col(\"y_velocity_right\") - pl.col(\"y_velocity_right_lagged\")) * 2000).alias(\"y_acceleration_right\")\n",
    "    ]).with_columns([\n",
    "        (pl.col(\"x_acceleration_left\").pow(2) + pl.col(\"y_acceleration_left\").pow(2)).sqrt().alias(\"total_acceleration_magnitude_left\"),\n",
    "        (pl.col(\"x_acceleration_right\").pow(2) + pl.col(\"y_acceleration_right\").pow(2)).sqrt().alias(\"total_acceleration_magnitude_right\")\n",
    "    ])\n",
    "\n",
    "    acceleration = df.group_by([\"experiment\", \"participant_id\"]).agg([\n",
    "        pl.col(\"total_acceleration_magnitude_left\").mean().alias(\"total_acceleration_magnitude_left_mean\"),\n",
    "        pl.col(\"total_acceleration_magnitude_left\").min().alias(\"total_acceleration_magnitude_left_min\"),\n",
    "        pl.col(\"total_acceleration_magnitude_left\").max().alias(\"total_acceleration_magnitude_left_max\"),\n",
    "        pl.col(\"total_acceleration_magnitude_left\").median().alias(\"total_acceleration_magnitude_left_median\"),\n",
    "        pl.col(\"total_acceleration_magnitude_left\").std().alias(\"total_acceleration_magnitude_left_std\"),\n",
    "\n",
    "        pl.col(\"total_acceleration_magnitude_right\").mean().alias(\"total_acceleration_magnitude_right_mean\"),\n",
    "        pl.col(\"total_acceleration_magnitude_right\").min().alias(\"total_acceleration_magnitude_right_min\"),\n",
    "        pl.col(\"total_acceleration_magnitude_right\").max().alias(\"total_acceleration_magnitude_right_max\"),\n",
    "        pl.col(\"total_acceleration_magnitude_right\").median().alias(\"total_acceleration_magnitude_right_median\"),\n",
    "        pl.col(\"total_acceleration_magnitude_right\").std().alias(\"total_acceleration_magnitude_right_std\")\n",
    "    ])\n",
    "\n",
    "    return acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 11:30:25,935 - INFO - 576518341.get_acceleration_feature_pl:15 - Started acceleration feature\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (159, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>experiment</th><th>participant_id</th><th>total_acceleration_magnitude_left_mean</th><th>total_acceleration_magnitude_left_min</th><th>total_acceleration_magnitude_left_max</th><th>total_acceleration_magnitude_left_median</th><th>total_acceleration_magnitude_left_std</th><th>total_acceleration_magnitude_right_mean</th><th>total_acceleration_magnitude_right_min</th><th>total_acceleration_magnitude_right_max</th><th>total_acceleration_magnitude_right_median</th><th>total_acceleration_magnitude_right_std</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;REACTION&quot;</td><td>228</td><td>1168.504499</td><td>0.0</td><td>80498.44719</td><td>824.621125</td><td>1848.183254</td><td>1253.00462</td><td>0.0</td><td>72089.94382</td><td>894.427191</td><td>2234.827616</td></tr><tr><td>&quot;REACTION&quot;</td><td>250</td><td>2001.069687</td><td>0.0</td><td>839214.037061</td><td>1000.0</td><td>15637.75885</td><td>2862.702345</td><td>0.0</td><td>699117.186171</td><td>1077.032961</td><td>12050.559675</td></tr><tr><td>&quot;REACTION&quot;</td><td>389</td><td>5517.936435</td><td>0.0</td><td>450317.310349</td><td>3984.971769</td><td>6144.386595</td><td>1871.424492</td><td>0.0</td><td>68170.374797</td><td>1442.22051</td><td>1713.942293</td></tr><tr><td>&quot;REACTION&quot;</td><td>382</td><td>1302.536136</td><td>0.0</td><td>91988.260121</td><td>721.110255</td><td>2916.573101</td><td>1504.203617</td><td>0.0</td><td>52803.408981</td><td>1077.032961</td><td>1875.208434</td></tr><tr><td>&quot;REACTION&quot;</td><td>336</td><td>1749.268286</td><td>0.0</td><td>100428.681162</td><td>1341.640786</td><td>2575.02595</td><td>1816.560171</td><td>0.0</td><td>152000.526315</td><td>1341.640786</td><td>3460.292738</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;REACTION&quot;</td><td>257</td><td>1526.154421</td><td>0.0</td><td>66616.814694</td><td>1000.0</td><td>3156.156059</td><td>1166.968774</td><td>0.0</td><td>67656.189665</td><td>632.455532</td><td>2942.709032</td></tr><tr><td>&quot;REACTION&quot;</td><td>378</td><td>1334.683534</td><td>0.0</td><td>132466.146619</td><td>721.110255</td><td>3727.230997</td><td>1355.79568</td><td>0.0</td><td>127422.60396</td><td>848.528137</td><td>2690.572802</td></tr><tr><td>&quot;REACTION&quot;</td><td>180</td><td>1037.317366</td><td>0.0</td><td>93955.308525</td><td>800.0</td><td>1603.040469</td><td>1175.904648</td><td>0.0</td><td>61691.490499</td><td>894.427191</td><td>1553.632166</td></tr><tr><td>&quot;REACTION&quot;</td><td>264</td><td>1720.397521</td><td>0.0</td><td>427466.255978</td><td>1019.803903</td><td>4710.854033</td><td>1745.40385</td><td>0.0</td><td>466055.490258</td><td>1000.0</td><td>6060.774611</td></tr><tr><td>&quot;REACTION&quot;</td><td>185</td><td>1633.178105</td><td>0.0</td><td>222649.230854</td><td>894.427191</td><td>5109.406188</td><td>2190.177997</td><td>0.0</td><td>171292.148098</td><td>1264.911064</td><td>6129.494037</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (159, 12)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ experimen ┆ participa ┆ total_acc ┆ total_acc ┆ … ┆ total_acc ┆ total_acc ┆ total_acc ┆ total_ac │\n",
       "│ t         ┆ nt_id     ┆ eleration ┆ eleration ┆   ┆ eleration ┆ eleration ┆ eleration ┆ celerati │\n",
       "│ ---       ┆ ---       ┆ _magnitud ┆ _magnitud ┆   ┆ _magnitud ┆ _magnitud ┆ _magnitud ┆ on_magni │\n",
       "│ str       ┆ i64       ┆ e_l…      ┆ e_l…      ┆   ┆ e_r…      ┆ e_r…      ┆ e_r…      ┆ tude_r…  │\n",
       "│           ┆           ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│           ┆           ┆ f64       ┆ f64       ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ REACTION  ┆ 228       ┆ 1168.5044 ┆ 0.0       ┆ … ┆ 0.0       ┆ 72089.943 ┆ 894.42719 ┆ 2234.827 │\n",
       "│           ┆           ┆ 99        ┆           ┆   ┆           ┆ 82        ┆ 1         ┆ 616      │\n",
       "│ REACTION  ┆ 250       ┆ 2001.0696 ┆ 0.0       ┆ … ┆ 0.0       ┆ 699117.18 ┆ 1077.0329 ┆ 12050.55 │\n",
       "│           ┆           ┆ 87        ┆           ┆   ┆           ┆ 6171      ┆ 61        ┆ 9675     │\n",
       "│ REACTION  ┆ 389       ┆ 5517.9364 ┆ 0.0       ┆ … ┆ 0.0       ┆ 68170.374 ┆ 1442.2205 ┆ 1713.942 │\n",
       "│           ┆           ┆ 35        ┆           ┆   ┆           ┆ 797       ┆ 1         ┆ 293      │\n",
       "│ REACTION  ┆ 382       ┆ 1302.5361 ┆ 0.0       ┆ … ┆ 0.0       ┆ 52803.408 ┆ 1077.0329 ┆ 1875.208 │\n",
       "│           ┆           ┆ 36        ┆           ┆   ┆           ┆ 981       ┆ 61        ┆ 434      │\n",
       "│ REACTION  ┆ 336       ┆ 1749.2682 ┆ 0.0       ┆ … ┆ 0.0       ┆ 152000.52 ┆ 1341.6407 ┆ 3460.292 │\n",
       "│           ┆           ┆ 86        ┆           ┆   ┆           ┆ 6315      ┆ 86        ┆ 738      │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ REACTION  ┆ 257       ┆ 1526.1544 ┆ 0.0       ┆ … ┆ 0.0       ┆ 67656.189 ┆ 632.45553 ┆ 2942.709 │\n",
       "│           ┆           ┆ 21        ┆           ┆   ┆           ┆ 665       ┆ 2         ┆ 032      │\n",
       "│ REACTION  ┆ 378       ┆ 1334.6835 ┆ 0.0       ┆ … ┆ 0.0       ┆ 127422.60 ┆ 848.52813 ┆ 2690.572 │\n",
       "│           ┆           ┆ 34        ┆           ┆   ┆           ┆ 396       ┆ 7         ┆ 802      │\n",
       "│ REACTION  ┆ 180       ┆ 1037.3173 ┆ 0.0       ┆ … ┆ 0.0       ┆ 61691.490 ┆ 894.42719 ┆ 1553.632 │\n",
       "│           ┆           ┆ 66        ┆           ┆   ┆           ┆ 499       ┆ 1         ┆ 166      │\n",
       "│ REACTION  ┆ 264       ┆ 1720.3975 ┆ 0.0       ┆ … ┆ 0.0       ┆ 466055.49 ┆ 1000.0    ┆ 6060.774 │\n",
       "│           ┆           ┆ 21        ┆           ┆   ┆           ┆ 0258      ┆           ┆ 611      │\n",
       "│ REACTION  ┆ 185       ┆ 1633.1781 ┆ 0.0       ┆ … ┆ 0.0       ┆ 171292.14 ┆ 1264.9110 ┆ 6129.494 │\n",
       "│           ┆           ┆ 05        ┆           ┆   ┆           ┆ 8098      ┆ 64        ┆ 037      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_acceleration_feature_pl(pl.from_dataframe(df_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 11:30:33,309 - INFO - 654501450.get_acceleration_feature:12 - Extracting acceleration\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_acceleration_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m, in \u001b[0;36mget_acceleration_feature\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Finds acceleration features for anti saccade experiment\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    {'total_acceleration_magnitude_left', 'total_acceleration_magnitude_right'} x {np.mean, np.min, np.max, np.median, np.std}\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting acceleration\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m acceleration \u001b[38;5;241m=\u001b[39m (\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparticipant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrial_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_left\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_left\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_right\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_right\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_left\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_left_lagged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_left\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_left_lagged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_right\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_velocity_right_lagged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_right\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_velocity_right_lagged\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 19\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_acceleration_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_velocity_left\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_velocity_left_lagged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_acceleration_left\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_velocity_left\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_velocity_left_lagged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_acceleration_right\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_velocity_right\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_velocity_right_lagged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_acceleration_right\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_velocity_right\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_velocity_right_lagged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;241m.\u001b[39massign(total_acceleration_magnitude_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msqrt( np\u001b[38;5;241m.\u001b[39mpower(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_acceleration_left\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_acceleration_left\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     24\u001b[0m         total_acceleration_magnitude_right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msqrt( np\u001b[38;5;241m.\u001b[39mpower(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_acceleration_right\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_acceleration_right\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_acceleration_magnitude_left\u001b[39m\u001b[38;5;124m'\u001b[39m: [np\u001b[38;5;241m.\u001b[39mmean, np\u001b[38;5;241m.\u001b[39mmin, np\u001b[38;5;241m.\u001b[39mmax, np\u001b[38;5;241m.\u001b[39mmedian, np\u001b[38;5;241m.\u001b[39mstd],\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_acceleration_magnitude_right\u001b[39m\u001b[38;5;124m'\u001b[39m: [np\u001b[38;5;241m.\u001b[39mmean, np\u001b[38;5;241m.\u001b[39mmin, np\u001b[38;5;241m.\u001b[39mmax, np\u001b[38;5;241m.\u001b[39mmedian, np\u001b[38;5;241m.\u001b[39mstd]\n\u001b[1;32m     28\u001b[0m     })\n\u001b[1;32m     29\u001b[0m \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     30\u001b[0m \u001b[38;5;241m.\u001b[39mpipe(rename_columns)\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acceleration\n",
      "File \u001b[0;32m~/Documents/Github/Analyzing-concussions-through-eyetracking-measurements/.venv/lib/python3.12/site-packages/pandas/core/frame.py:5236\u001b[0m, in \u001b[0;36mDataFrame.assign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   5174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21massign\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   5175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5176\u001b[0m \u001b[38;5;124;03m    Assign new columns to a DataFrame.\u001b[39;00m\n\u001b[1;32m   5177\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5234\u001b[0m \u001b[38;5;124;03m    Berkeley    25.0    77.0  298.15\u001b[39;00m\n\u001b[1;32m   5235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5238\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   5239\u001b[0m         data[k] \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(v, data)\n",
      "File \u001b[0;32m~/Documents/Github/Analyzing-concussions-through-eyetracking-measurements/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6815\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Github/Analyzing-concussions-through-eyetracking-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Github/Analyzing-concussions-through-eyetracking-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Documents/Github/Analyzing-concussions-through-eyetracking-measurements/.venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_acceleration_feature(df_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
